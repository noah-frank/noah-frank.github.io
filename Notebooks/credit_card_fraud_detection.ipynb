{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Detecting Credit Fraud\n",
    "\n",
    "Credit card fraud has become a major issue for consumers and financial institutions alike. While the data surrounding credit card transactions has been growing in recent years, data in itself cannot stop financial fraud. However, machine learning models can be used to detect fraud in real time and prevent losses for legitimate users. \n",
    "\n",
    "This notebook explores a credit card fraud dataset that records details from over 280,000 credit card transactions and the fraud status of each. This data is then used to create models that can help in detecting and preventing credit card fraud. \n",
    "\n",
    "The data set was posted on kaggle by [Machine Learning Group - ULB.](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Data\n",
    "\n",
    "Below, the data is imported using the `kagglehub` library and stored in the `df` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.10)\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import SGD, Nadam\n",
    "\n",
    "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
    "df = pd.read_csv(path + \"/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Now that the data has been imported, some basic exploratory data analysis can be performed. \n",
    "\n",
    "> \"exploratory data analysis (EDA) is an approach of analyzing data sets to summarize their main characteristics, often using statistical graphics and other data visualization methods.\" [(Wikipedia)](https://en.wikipedia.org/wiki/Exploratory_data_analysis)\n",
    "\n",
    "Below, the first 5 rows of the dataset are shown: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total there are 31 rows, 30 features (Time, V1-V28, Amount) and one target (Class). The class is just a binary value, where 0 represents a legitimate transaction and 1 represents fraud. Below some information about each column is shown: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The are 284,000 non-null records in the dataset, with all features represented by floats and the target represented by an integer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Variables\n",
    "\n",
    "In order to understand the dataset fully, several variables can be plotted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time\n",
    "\n",
    "The time column is a represenation of the time (in seconds) between the first transaction and the current transaction: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"Time\"].hist(bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason two high frequency areas are shown is because this data was recorded over two days, so the two dips are most likely the early morning on each day, with the tops of the curves representing the highest frequency times during the day. \n",
    "\n",
    "Although the time is a good variable to include, it will need to be scaled in order to be more useful for training models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Amount\n",
    "\n",
    "The Amount column is simply the transaction amount. Below, the top 10 amounts are shown along with a histogram of the Amount column: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274771    25691.16\n",
      "58465     19656.53\n",
      "151296    18910.00\n",
      "46841     12910.93\n",
      "54018     11898.09\n",
      "169457    11789.84\n",
      "284249    10199.44\n",
      "227921    10000.00\n",
      "74699      8790.26\n",
      "245474     8787.00\n",
      "Name: Amount, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df[\"Amount\"].sort_values(ascending=False).head(10))\n",
    "\n",
    "df[\"Amount\"].hist(bins=100, figsize=(12, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram above shows that the majority of transactions were relatively small amounts, with a few large transactions causing the chart to display large value along the X-axis. The 10 highest-amount transactions are shown above the chart, with the only 8 being 10,000 or greater. Scaling will help even out this features and counteract skewing of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class\n",
    "\n",
    "The Class column represents the target. Below, a function is defined to plot the negative and positive classes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bin(y_in): # Function definition\n",
    "    # y_in = df[\"Class\"]\n",
    "    bin_count = np.bincount(y_in)\n",
    "    count_df = pd.DataFrame(data={\"0\": bin_count[0], \"1\": bin_count[1]}, index=[0])\n",
    "\n",
    "    count_df.plot(kind=\"bar\")\n",
    "    return count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>284315</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1\n",
       "0  284315  492"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_bin(df[\"Class\"]) # Function call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, over 284,000 transactions were legitimate, with only 492 being fraudulent. While its good that so little fraud is happening proportionally to the overall number of transactions, this makes it much harder to train a model to detect fraud. This issue will be addressed in the preprocessing section.\n",
    "\n",
    "While features V1-V28 could be plotted, they have already been transformed and scaled to protect customer information, so they will be used as is going forward. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Below, some preprocessing steps are taken to prepare the data for use in a model. First, the features and target are defined: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((284807, 30), (284807,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = df.drop(\"Class\", axis=1), df[\"Class\"]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting\n",
    "\n",
    "While the majority of the data will be utilized by the model to learn the underlying patterns, some data needs to be set aside in order to similuate real world data. Below, an 80-10-10 train-validation-test split is performed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((256326, 30), (14241, 30), (14240, 30), (256326,), (14240,), (14241,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 80% train\n",
    "# 10% validation\n",
    "# 10% test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42) \n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test, random_state=42) \n",
    "\n",
    "X_train.shape, X_test.shape, X_val.shape, y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "\n",
    "The Time and Amount columns are scaled so outlying data doesn't skew the model's predictions. This should help the models make more accurate predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[[\"Time\", \"Amount\"]])\n",
    "\n",
    "X_train[[\"Time\", \"Amount\"]] = scaler.transform(X_train[[\"Time\", \"Amount\"]])\n",
    "X_val[[\"Time\", \"Amount\"]] = scaler.transform(X_val[[\"Time\", \"Amount\"]])\n",
    "X_test[[\"Time\", \"Amount\"]] = scaler.transform(X_test[[\"Time\", \"Amount\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling\n",
    "\n",
    "Because the target contains a much greater number of negative instances, the training data needs to be oversampled in order for the models to learn the patterns when the fraud occurs. Below, random oversampling is used to transform the training dataset. \n",
    "\n",
    "> [Random Oversampling](https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis) involves supplementing the training data with multiple copies of some of the minority classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train, y_train = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255883</td>\n",
       "      <td>255883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1\n",
       "0  255883  255883"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_bin(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After oversampling, there are an equal amount of negative and positive instances. \n",
    "\n",
    "Now that the data has been prepared, it can be used to train and test models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "In total 3 models will be built with slightly different compositions. All will incorporate multiple dense layers, with batch normalization and dropout. \n",
    "\n",
    "### Metrics\n",
    "\n",
    "Because this is a binary classification problem, some basic terminology is defined below: \n",
    "\n",
    "* True Positive (TP): the true instances that are correctly classified as true\n",
    "* False Positive (FP): the false instances that are incorrectly classified as true\n",
    "* True Negative (TN): the false instances that are correctly classified as false\n",
    "* False Negatives (FN): the true instances that are incorrectly classified as false\n",
    "\n",
    "The goal of classification is to classify all instances as either true positives or true negatives, while getting as few false positives and false negatives as possible. The metrics used in reaching this goal are defined below: \n",
    "* Accuracy: the overall percentage of instances that were correct: (TP + TN) / Total\n",
    "* Precision: the percentage of positive <i>predictions</i> that were correct: TP / (TP + FP)\n",
    "* Recall: the percentage of positive <i>instances</i> that were predicted to be positive: TP / (TP + FN)\n",
    "\n",
    "In each metric, a higher score is better. However, there are can be trade-offs between precision and recall. For the models below, a balance between precision and recall is the goal (along with high accuracy). \n",
    "\n",
    "Now that the background has been explained, the model building can begin. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1\n",
    "\n",
    "The first model contains two 256-unit dense layers with dropout layers of 0.35, which are fed to a dense 32-unit layer and onto the output. The Nadam optimizer is used with a learning rate of 0.0001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2ms/step - accuracy: 0.9522 - loss: 0.1186 - precision: 0.9661 - recall: 0.9366 - val_accuracy: 0.9934 - val_loss: 0.0206 - val_precision: 0.1875 - val_recall: 0.8750\n",
      "Epoch 2/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0210 - precision: 0.9913 - recall: 0.9951 - val_accuracy: 0.9966 - val_loss: 0.0138 - val_precision: 0.3134 - val_recall: 0.8750\n",
      "Epoch 3/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - accuracy: 0.9964 - loss: 0.0118 - precision: 0.9951 - recall: 0.9977 - val_accuracy: 0.9971 - val_loss: 0.0124 - val_precision: 0.3559 - val_recall: 0.8750\n",
      "Epoch 4/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2ms/step - accuracy: 0.9977 - loss: 0.0084 - precision: 0.9967 - recall: 0.9987 - val_accuracy: 0.9976 - val_loss: 0.0107 - val_precision: 0.4038 - val_recall: 0.8750\n",
      "Epoch 5/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0066 - precision: 0.9975 - recall: 0.9989 - val_accuracy: 0.9984 - val_loss: 0.0092 - val_precision: 0.5122 - val_recall: 0.8750\n",
      "Epoch 6/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0054 - precision: 0.9979 - recall: 0.9991 - val_accuracy: 0.9984 - val_loss: 0.0092 - val_precision: 0.5122 - val_recall: 0.8750\n",
      "Epoch 7/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0047 - precision: 0.9983 - recall: 0.9993 - val_accuracy: 0.9984 - val_loss: 0.0086 - val_precision: 0.5122 - val_recall: 0.8750\n",
      "Epoch 8/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0043 - precision: 0.9984 - recall: 0.9994 - val_accuracy: 0.9987 - val_loss: 0.0083 - val_precision: 0.5676 - val_recall: 0.8750\n",
      "Epoch 9/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0039 - precision: 0.9986 - recall: 0.9995 - val_accuracy: 0.9989 - val_loss: 0.0076 - val_precision: 0.6176 - val_recall: 0.8750\n",
      "Epoch 10/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0036 - precision: 0.9987 - recall: 0.9995 - val_accuracy: 0.9990 - val_loss: 0.0077 - val_precision: 0.6562 - val_recall: 0.8750\n",
      "Epoch 11/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0032 - precision: 0.9988 - recall: 0.9997 - val_accuracy: 0.9988 - val_loss: 0.0073 - val_precision: 0.6061 - val_recall: 0.8333\n",
      "Epoch 12/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0031 - precision: 0.9989 - recall: 0.9996 - val_accuracy: 0.9987 - val_loss: 0.0078 - val_precision: 0.5882 - val_recall: 0.8333\n",
      "Epoch 13/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0028 - precision: 0.9990 - recall: 0.9996 - val_accuracy: 0.9990 - val_loss: 0.0075 - val_precision: 0.6667 - val_recall: 0.8333\n",
      "Epoch 14/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0030 - precision: 0.9989 - recall: 0.9997 - val_accuracy: 0.9989 - val_loss: 0.0074 - val_precision: 0.6250 - val_recall: 0.8333\n",
      "Epoch 15/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0028 - precision: 0.9990 - recall: 0.9997 - val_accuracy: 0.9990 - val_loss: 0.0072 - val_precision: 0.6667 - val_recall: 0.8333\n",
      "Epoch 16/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0025 - precision: 0.9991 - recall: 0.9997 - val_accuracy: 0.9993 - val_loss: 0.0070 - val_precision: 0.7692 - val_recall: 0.8333\n",
      "Epoch 17/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0022 - precision: 0.9992 - recall: 0.9996 - val_accuracy: 0.9991 - val_loss: 0.0072 - val_precision: 0.6897 - val_recall: 0.8333\n",
      "Epoch 18/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0022 - precision: 0.9992 - recall: 0.9997 - val_accuracy: 0.9993 - val_loss: 0.0069 - val_precision: 0.7692 - val_recall: 0.8333\n",
      "Epoch 19/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0022 - precision: 0.9992 - recall: 0.9997 - val_accuracy: 0.9993 - val_loss: 0.0068 - val_precision: 0.7692 - val_recall: 0.8333\n",
      "Epoch 20/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0021 - precision: 0.9993 - recall: 0.9998 - val_accuracy: 0.9992 - val_loss: 0.0072 - val_precision: 0.7143 - val_recall: 0.8333\n",
      "Epoch 21/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0021 - precision: 0.9993 - recall: 0.9997 - val_accuracy: 0.9992 - val_loss: 0.0069 - val_precision: 0.7407 - val_recall: 0.8333\n",
      "Epoch 22/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0021 - precision: 0.9993 - recall: 0.9997 - val_accuracy: 0.9992 - val_loss: 0.0068 - val_precision: 0.7143 - val_recall: 0.8333\n",
      "Epoch 23/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0019 - precision: 0.9993 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0066 - val_precision: 0.8000 - val_recall: 0.8333\n",
      "Epoch 24/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0018 - precision: 0.9993 - recall: 0.9998 - val_accuracy: 0.9991 - val_loss: 0.0078 - val_precision: 0.6897 - val_recall: 0.8333\n",
      "Epoch 25/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0019 - precision: 0.9994 - recall: 0.9998 - val_accuracy: 0.9993 - val_loss: 0.0072 - val_precision: 0.7692 - val_recall: 0.8333\n",
      "Epoch 26/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0018 - precision: 0.9994 - recall: 0.9998 - val_accuracy: 0.9993 - val_loss: 0.0074 - val_precision: 0.7692 - val_recall: 0.8333\n",
      "Epoch 27/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0017 - precision: 0.9994 - recall: 0.9997 - val_accuracy: 0.9992 - val_loss: 0.0072 - val_precision: 0.7407 - val_recall: 0.8333\n",
      "Epoch 28/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0015 - precision: 0.9994 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0069 - val_precision: 0.8000 - val_recall: 0.8333\n",
      "Epoch 29/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0016 - precision: 0.9994 - recall: 0.9998 - val_accuracy: 0.9993 - val_loss: 0.0071 - val_precision: 0.7692 - val_recall: 0.8333\n",
      "Epoch 30/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0017 - precision: 0.9994 - recall: 0.9997 - val_accuracy: 0.9994 - val_loss: 0.0072 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 31/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0017 - precision: 0.9994 - recall: 0.9997 - val_accuracy: 0.9991 - val_loss: 0.0069 - val_precision: 0.6897 - val_recall: 0.8333\n",
      "Epoch 32/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0016 - precision: 0.9994 - recall: 0.9999 - val_accuracy: 0.9993 - val_loss: 0.0069 - val_precision: 0.7692 - val_recall: 0.8333\n",
      "Epoch 33/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0015 - precision: 0.9995 - recall: 0.9998 - val_accuracy: 0.9992 - val_loss: 0.0074 - val_precision: 0.7407 - val_recall: 0.8333\n",
      "Epoch 34/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0016 - precision: 0.9994 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0066 - val_precision: 0.8000 - val_recall: 0.8333\n",
      "Epoch 35/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0016 - precision: 0.9995 - recall: 0.9997 - val_accuracy: 0.9994 - val_loss: 0.0067 - val_precision: 0.8000 - val_recall: 0.8333\n",
      "Epoch 36/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0012 - precision: 0.9995 - recall: 0.9999 - val_accuracy: 0.9994 - val_loss: 0.0066 - val_precision: 0.8000 - val_recall: 0.8333\n",
      "Epoch 37/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0015 - precision: 0.9994 - recall: 0.9998 - val_accuracy: 0.9992 - val_loss: 0.0069 - val_precision: 0.7407 - val_recall: 0.8333\n",
      "Epoch 38/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0014 - precision: 0.9995 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0071 - val_precision: 0.8000 - val_recall: 0.8333\n",
      "Epoch 39/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0013 - precision: 0.9995 - recall: 0.9998 - val_accuracy: 0.9993 - val_loss: 0.0070 - val_precision: 0.7692 - val_recall: 0.8333\n",
      "Epoch 40/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0015 - precision: 0.9995 - recall: 0.9997 - val_accuracy: 0.9994 - val_loss: 0.0065 - val_precision: 0.8000 - val_recall: 0.8333\n",
      "Epoch 41/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0014 - precision: 0.9995 - recall: 0.9998 - val_accuracy: 0.9993 - val_loss: 0.0066 - val_precision: 0.7692 - val_recall: 0.8333\n",
      "Epoch 42/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0013 - precision: 0.9995 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0068 - val_precision: 0.8000 - val_recall: 0.8333\n",
      "Epoch 43/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0016 - precision: 0.9995 - recall: 0.9997 - val_accuracy: 0.9994 - val_loss: 0.0064 - val_precision: 0.8000 - val_recall: 0.8333\n",
      "Epoch 44/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0015 - precision: 0.9994 - recall: 0.9997 - val_accuracy: 0.9992 - val_loss: 0.0067 - val_precision: 0.7407 - val_recall: 0.8333\n",
      "Epoch 45/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0014 - precision: 0.9995 - recall: 0.9999 - val_accuracy: 0.9994 - val_loss: 0.0067 - val_precision: 0.8000 - val_recall: 0.8333\n",
      "Epoch 46/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0012 - precision: 0.9996 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0066 - val_precision: 0.8000 - val_recall: 0.8333\n",
      "Epoch 47/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0012 - precision: 0.9996 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0069 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 48/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0014 - precision: 0.9995 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0064 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 49/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0012 - precision: 0.9995 - recall: 0.9998 - val_accuracy: 0.9995 - val_loss: 0.0067 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 50/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0014 - precision: 0.9995 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0069 - val_precision: 0.8000 - val_recall: 0.8333\n",
      "Epoch 51/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0013 - precision: 0.9996 - recall: 0.9998 - val_accuracy: 0.9993 - val_loss: 0.0067 - val_precision: 0.7692 - val_recall: 0.8333\n",
      "Epoch 52/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0012 - precision: 0.9996 - recall: 0.9999 - val_accuracy: 0.9995 - val_loss: 0.0065 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 53/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0013 - precision: 0.9996 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0067 - val_precision: 0.8000 - val_recall: 0.8333\n",
      "Epoch 54/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0013 - precision: 0.9996 - recall: 0.9998 - val_accuracy: 0.9993 - val_loss: 0.0065 - val_precision: 0.7692 - val_recall: 0.8333\n",
      "Epoch 55/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0012 - precision: 0.9996 - recall: 0.9999 - val_accuracy: 0.9995 - val_loss: 0.0065 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 56/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0011 - precision: 0.9997 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0065 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 57/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0011 - precision: 0.9995 - recall: 0.9998 - val_accuracy: 0.9995 - val_loss: 0.0067 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 58/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0013 - precision: 0.9995 - recall: 0.9998 - val_accuracy: 0.9995 - val_loss: 0.0068 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 59/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0013 - precision: 0.9996 - recall: 0.9998 - val_accuracy: 0.9995 - val_loss: 0.0064 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 60/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0011 - precision: 0.9996 - recall: 0.9999 - val_accuracy: 0.9994 - val_loss: 0.0072 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 61/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0013 - precision: 0.9995 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0069 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 62/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0012 - precision: 0.9996 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0063 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 63/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0011 - precision: 0.9996 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0064 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 64/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0011 - precision: 0.9996 - recall: 0.9998 - val_accuracy: 0.9995 - val_loss: 0.0063 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 65/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0010 - precision: 0.9997 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0063 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 66/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0012 - precision: 0.9996 - recall: 0.9998 - val_accuracy: 0.9995 - val_loss: 0.0063 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 67/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0011 - precision: 0.9996 - recall: 0.9999 - val_accuracy: 0.9995 - val_loss: 0.0064 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 68/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0012 - precision: 0.9996 - recall: 0.9999 - val_accuracy: 0.9995 - val_loss: 0.0063 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 69/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0011 - precision: 0.9996 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0069 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 70/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0011 - precision: 0.9996 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0068 - val_precision: 0.8000 - val_recall: 0.8333\n",
      "Epoch 71/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 9.9832e-04 - precision: 0.9996 - recall: 0.9999 - val_accuracy: 0.9994 - val_loss: 0.0070 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 72/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 9.2155e-04 - precision: 0.9997 - recall: 0.9998 - val_accuracy: 0.9993 - val_loss: 0.0068 - val_precision: 0.7692 - val_recall: 0.8333\n",
      "Epoch 73/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0012 - precision: 0.9996 - recall: 0.9999 - val_accuracy: 0.9995 - val_loss: 0.0066 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 74/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0011 - precision: 0.9996 - recall: 0.9998 - val_accuracy: 0.9995 - val_loss: 0.0075 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 75/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0010 - precision: 0.9996 - recall: 0.9998 - val_accuracy: 0.9996 - val_loss: 0.0069 - val_precision: 0.9091 - val_recall: 0.8333\n",
      "Epoch 76/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 9.6756e-04 - precision: 0.9996 - recall: 0.9999 - val_accuracy: 0.9995 - val_loss: 0.0074 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 77/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0011 - precision: 0.9997 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0072 - val_precision: 0.8000 - val_recall: 0.8333\n",
      "Epoch 78/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 9.3845e-04 - precision: 0.9996 - recall: 0.9998 - val_accuracy: 0.9995 - val_loss: 0.0066 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 79/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 9.2617e-04 - precision: 0.9996 - recall: 0.9999 - val_accuracy: 0.9994 - val_loss: 0.0068 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 80/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0012 - precision: 0.9996 - recall: 0.9999 - val_accuracy: 0.9994 - val_loss: 0.0073 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 81/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 8.8162e-04 - precision: 0.9997 - recall: 0.9999 - val_accuracy: 0.9995 - val_loss: 0.0074 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 82/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0010 - precision: 0.9996 - recall: 0.9998 - val_accuracy: 0.9995 - val_loss: 0.0071 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 83/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0010 - precision: 0.9996 - recall: 0.9999 - val_accuracy: 0.9995 - val_loss: 0.0069 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 84/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0011 - precision: 0.9996 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0068 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 85/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0010 - precision: 0.9996 - recall: 0.9999 - val_accuracy: 0.9995 - val_loss: 0.0065 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 86/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0010 - precision: 0.9997 - recall: 0.9999 - val_accuracy: 0.9995 - val_loss: 0.0070 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 87/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 9.9105e-04 - precision: 0.9997 - recall: 0.9998 - val_accuracy: 0.9995 - val_loss: 0.0067 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 88/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0010 - precision: 0.9996 - recall: 0.9998 - val_accuracy: 0.9995 - val_loss: 0.0072 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 89/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 9.3822e-04 - precision: 0.9997 - recall: 0.9998 - val_accuracy: 0.9995 - val_loss: 0.0069 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 90/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0010 - precision: 0.9997 - recall: 0.9998 - val_accuracy: 0.9995 - val_loss: 0.0071 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 91/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 8.3030e-04 - precision: 0.9997 - recall: 0.9999 - val_accuracy: 0.9995 - val_loss: 0.0074 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 92/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 9.5979e-04 - precision: 0.9997 - recall: 0.9998 - val_accuracy: 0.9995 - val_loss: 0.0075 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 93/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 8.7412e-04 - precision: 0.9997 - recall: 0.9999 - val_accuracy: 0.9994 - val_loss: 0.0074 - val_precision: 0.8000 - val_recall: 0.8333\n",
      "Epoch 94/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 9.3179e-04 - precision: 0.9997 - recall: 0.9998 - val_accuracy: 0.9995 - val_loss: 0.0070 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 95/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 9.5059e-04 - precision: 0.9997 - recall: 0.9999 - val_accuracy: 0.9995 - val_loss: 0.0074 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 96/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 9.7914e-04 - precision: 0.9996 - recall: 0.9998 - val_accuracy: 0.9995 - val_loss: 0.0073 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 97/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 8.5427e-04 - precision: 0.9997 - recall: 0.9999 - val_accuracy: 0.9995 - val_loss: 0.0070 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 98/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0010 - precision: 0.9996 - recall: 0.9998 - val_accuracy: 0.9995 - val_loss: 0.0070 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 99/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 7.8055e-04 - precision: 0.9996 - recall: 0.9999 - val_accuracy: 0.9995 - val_loss: 0.0070 - val_precision: 0.8696 - val_recall: 0.8333\n",
      "Epoch 100/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 7.9046e-04 - precision: 0.9997 - recall: 0.9999 - val_accuracy: 0.9995 - val_loss: 0.0073 - val_precision: 0.8696 - val_recall: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x206698ba9f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model1 = Sequential([\n",
    "\n",
    "    InputLayer(X_train.shape[1:]),\n",
    "    \n",
    "    Dense(256, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.35),\n",
    "\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.35),\n",
    "    \n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model1.compile(loss=BinaryCrossentropy(), optimizer=Nadam(learning_rate=0.0001), metrics=[\"accuracy\", \"precision\", \"recall\"])\n",
    "model1.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final validation metrics for `model1` were: \n",
    "* Accuracy: 0.99\n",
    "* Precision: 0.86\n",
    "* Recall: 0.83\n",
    "\n",
    "Below, `model1` is scored on the testing set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 937us/step - accuracy: 0.9993 - loss: 0.0123 - precision: 0.7828 - recall: 0.8533       \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0062684593722224236,\n",
       " 0.9995084404945374,\n",
       " 0.8214285969734192,\n",
       " 0.9200000166893005]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy was near perfect, but precision and recall were not quite as good. Although the latter two metrics are not ideal, the model did fairly well on the testing data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2\n",
    "\n",
    "The second model contains four 256-unit dense layers with dropout layers of 0.35, which are fed to a dense 32-unit layer and onto the output. Once again, the Nadam optimizer is used, but with a learning rate of 0.001 instead of 0.0001. The larget network should hopefully be able to learn more complex relationships in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3ms/step - accuracy: 0.9713 - loss: 0.0735 - precision: 0.9718 - recall: 0.9708 - val_accuracy: 0.9952 - val_loss: 0.0147 - val_precision: 0.2442 - val_recall: 0.8750\n",
      "Epoch 2/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0159 - precision: 0.9940 - recall: 0.9969 - val_accuracy: 0.9968 - val_loss: 0.0116 - val_precision: 0.3226 - val_recall: 0.8333\n",
      "Epoch 3/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0111 - precision: 0.9958 - recall: 0.9981 - val_accuracy: 0.9980 - val_loss: 0.0085 - val_precision: 0.4468 - val_recall: 0.8750\n",
      "Epoch 4/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0090 - precision: 0.9967 - recall: 0.9987 - val_accuracy: 0.9980 - val_loss: 0.0082 - val_precision: 0.4565 - val_recall: 0.8750\n",
      "Epoch 5/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0078 - precision: 0.9973 - recall: 0.9988 - val_accuracy: 0.9978 - val_loss: 0.0099 - val_precision: 0.4286 - val_recall: 0.8750\n",
      "Epoch 6/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0071 - precision: 0.9974 - recall: 0.9990 - val_accuracy: 0.9983 - val_loss: 0.0071 - val_precision: 0.5000 - val_recall: 0.8750\n",
      "Epoch 7/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0066 - precision: 0.9977 - recall: 0.9990 - val_accuracy: 0.9977 - val_loss: 0.0094 - val_precision: 0.4118 - val_recall: 0.8750\n",
      "Epoch 8/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0059 - precision: 0.9979 - recall: 0.9992 - val_accuracy: 0.9985 - val_loss: 0.0079 - val_precision: 0.5250 - val_recall: 0.8750\n",
      "Epoch 9/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0052 - precision: 0.9982 - recall: 0.9994 - val_accuracy: 0.9989 - val_loss: 0.0068 - val_precision: 0.6176 - val_recall: 0.8750\n",
      "Epoch 10/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0056 - precision: 0.9981 - recall: 0.9993 - val_accuracy: 0.9989 - val_loss: 0.0063 - val_precision: 0.6452 - val_recall: 0.8333\n",
      "Epoch 11/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0049 - precision: 0.9983 - recall: 0.9994 - val_accuracy: 0.9987 - val_loss: 0.0064 - val_precision: 0.5882 - val_recall: 0.8333\n",
      "Epoch 12/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0048 - precision: 0.9984 - recall: 0.9993 - val_accuracy: 0.9984 - val_loss: 0.0081 - val_precision: 0.5122 - val_recall: 0.8750\n",
      "Epoch 13/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0043 - precision: 0.9985 - recall: 0.9995 - val_accuracy: 0.9987 - val_loss: 0.0068 - val_precision: 0.5833 - val_recall: 0.8750\n",
      "Epoch 14/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0044 - precision: 0.9986 - recall: 0.9994 - val_accuracy: 0.9989 - val_loss: 0.0073 - val_precision: 0.6176 - val_recall: 0.8750\n",
      "Epoch 15/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0043 - precision: 0.9987 - recall: 0.9994 - val_accuracy: 0.9987 - val_loss: 0.0084 - val_precision: 0.5676 - val_recall: 0.8750\n",
      "Epoch 16/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0040 - precision: 0.9987 - recall: 0.9996 - val_accuracy: 0.9987 - val_loss: 0.0082 - val_precision: 0.5833 - val_recall: 0.8750\n",
      "Epoch 17/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0043 - precision: 0.9985 - recall: 0.9995 - val_accuracy: 0.9991 - val_loss: 0.0063 - val_precision: 0.6897 - val_recall: 0.8333\n",
      "Epoch 18/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0039 - precision: 0.9988 - recall: 0.9995 - val_accuracy: 0.9989 - val_loss: 0.0063 - val_precision: 0.6364 - val_recall: 0.8750\n",
      "Epoch 19/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0039 - precision: 0.9988 - recall: 0.9995 - val_accuracy: 0.9989 - val_loss: 0.0071 - val_precision: 0.6364 - val_recall: 0.8750\n",
      "Epoch 20/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0042 - precision: 0.9987 - recall: 0.9995 - val_accuracy: 0.9991 - val_loss: 0.0069 - val_precision: 0.6897 - val_recall: 0.8333\n",
      "Epoch 21/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0034 - precision: 0.9988 - recall: 0.9996 - val_accuracy: 0.9988 - val_loss: 0.0071 - val_precision: 0.6000 - val_recall: 0.8750\n",
      "Epoch 22/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0036 - precision: 0.9988 - recall: 0.9995 - val_accuracy: 0.9990 - val_loss: 0.0071 - val_precision: 0.6562 - val_recall: 0.8750\n",
      "Epoch 23/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0039 - precision: 0.9987 - recall: 0.9995 - val_accuracy: 0.9993 - val_loss: 0.0058 - val_precision: 0.7692 - val_recall: 0.8333\n",
      "Epoch 24/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0033 - precision: 0.9990 - recall: 0.9996 - val_accuracy: 0.9989 - val_loss: 0.0068 - val_precision: 0.6364 - val_recall: 0.8750\n",
      "Epoch 25/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0035 - precision: 0.9989 - recall: 0.9996 - val_accuracy: 0.9993 - val_loss: 0.0058 - val_precision: 0.7692 - val_recall: 0.8333\n",
      "Epoch 26/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0030 - precision: 0.9991 - recall: 0.9997 - val_accuracy: 0.9992 - val_loss: 0.0068 - val_precision: 0.7000 - val_recall: 0.8750\n",
      "Epoch 27/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0033 - precision: 0.9989 - recall: 0.9996 - val_accuracy: 0.9989 - val_loss: 0.0086 - val_precision: 0.6364 - val_recall: 0.8750\n",
      "Epoch 28/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0034 - precision: 0.9990 - recall: 0.9996 - val_accuracy: 0.9990 - val_loss: 0.0100 - val_precision: 0.6667 - val_recall: 0.8333\n",
      "Epoch 29/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0033 - precision: 0.9990 - recall: 0.9997 - val_accuracy: 0.9992 - val_loss: 0.0086 - val_precision: 0.7407 - val_recall: 0.8333\n",
      "Epoch 30/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0032 - precision: 0.9990 - recall: 0.9997 - val_accuracy: 0.9992 - val_loss: 0.0066 - val_precision: 0.7143 - val_recall: 0.8333\n",
      "Epoch 31/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0031 - precision: 0.9990 - recall: 0.9997 - val_accuracy: 0.9989 - val_loss: 0.0078 - val_precision: 0.6452 - val_recall: 0.8333\n",
      "Epoch 32/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0037 - precision: 0.9989 - recall: 0.9995 - val_accuracy: 0.9989 - val_loss: 0.0055 - val_precision: 0.6452 - val_recall: 0.8333\n",
      "Epoch 33/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0030 - precision: 0.9990 - recall: 0.9996 - val_accuracy: 0.9987 - val_loss: 0.0078 - val_precision: 0.5938 - val_recall: 0.7917\n",
      "Epoch 34/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0029 - precision: 0.9990 - recall: 0.9997 - val_accuracy: 0.9989 - val_loss: 0.0067 - val_precision: 0.6176 - val_recall: 0.8750\n",
      "Epoch 35/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0030 - precision: 0.9990 - recall: 0.9997 - val_accuracy: 0.9990 - val_loss: 0.0063 - val_precision: 0.6667 - val_recall: 0.8333\n",
      "Epoch 36/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0030 - precision: 0.9992 - recall: 0.9997 - val_accuracy: 0.9992 - val_loss: 0.0060 - val_precision: 0.7407 - val_recall: 0.8333\n",
      "Epoch 37/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0028 - precision: 0.9991 - recall: 0.9996 - val_accuracy: 0.9993 - val_loss: 0.0071 - val_precision: 0.7692 - val_recall: 0.8333\n",
      "Epoch 38/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0031 - precision: 0.9990 - recall: 0.9997 - val_accuracy: 0.9993 - val_loss: 0.0068 - val_precision: 0.7500 - val_recall: 0.8750\n",
      "Epoch 39/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0030 - precision: 0.9991 - recall: 0.9996 - val_accuracy: 0.9992 - val_loss: 0.0067 - val_precision: 0.7143 - val_recall: 0.8333\n",
      "Epoch 40/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0029 - precision: 0.9991 - recall: 0.9997 - val_accuracy: 0.9991 - val_loss: 0.0068 - val_precision: 0.6897 - val_recall: 0.8333\n",
      "Epoch 41/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0027 - precision: 0.9992 - recall: 0.9997 - val_accuracy: 0.9992 - val_loss: 0.0076 - val_precision: 0.7143 - val_recall: 0.8333\n",
      "Epoch 42/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0028 - precision: 0.9992 - recall: 0.9997 - val_accuracy: 0.9992 - val_loss: 0.0078 - val_precision: 0.7407 - val_recall: 0.8333\n",
      "Epoch 43/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0029 - precision: 0.9991 - recall: 0.9997 - val_accuracy: 0.9990 - val_loss: 0.0066 - val_precision: 0.6667 - val_recall: 0.8333\n",
      "Epoch 44/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0030 - precision: 0.9991 - recall: 0.9997 - val_accuracy: 0.9992 - val_loss: 0.0056 - val_precision: 0.7407 - val_recall: 0.8333\n",
      "Epoch 45/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0027 - precision: 0.9991 - recall: 0.9997 - val_accuracy: 0.9992 - val_loss: 0.0066 - val_precision: 0.7143 - val_recall: 0.8333\n",
      "Epoch 46/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0027 - precision: 0.9991 - recall: 0.9997 - val_accuracy: 0.9989 - val_loss: 0.0070 - val_precision: 0.6250 - val_recall: 0.8333\n",
      "Epoch 47/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0026 - precision: 0.9992 - recall: 0.9997 - val_accuracy: 0.9989 - val_loss: 0.0063 - val_precision: 0.6452 - val_recall: 0.8333\n",
      "Epoch 48/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0026 - precision: 0.9992 - recall: 0.9997 - val_accuracy: 0.9993 - val_loss: 0.0052 - val_precision: 0.7692 - val_recall: 0.8333\n",
      "Epoch 49/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0028 - precision: 0.9991 - recall: 0.9997 - val_accuracy: 0.9989 - val_loss: 0.0074 - val_precision: 0.6552 - val_recall: 0.7917\n",
      "Epoch 50/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0026 - precision: 0.9992 - recall: 0.9998 - val_accuracy: 0.9990 - val_loss: 0.0077 - val_precision: 0.6667 - val_recall: 0.8333\n",
      "Epoch 51/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0025 - precision: 0.9992 - recall: 0.9998 - val_accuracy: 0.9989 - val_loss: 0.0069 - val_precision: 0.6552 - val_recall: 0.7917\n",
      "Epoch 52/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0026 - precision: 0.9992 - recall: 0.9998 - val_accuracy: 0.9991 - val_loss: 0.0063 - val_precision: 0.6897 - val_recall: 0.8333\n",
      "Epoch 53/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0023 - precision: 0.9993 - recall: 0.9998 - val_accuracy: 0.9988 - val_loss: 0.0067 - val_precision: 0.6000 - val_recall: 0.8750\n",
      "Epoch 54/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0025 - precision: 0.9992 - recall: 0.9998 - val_accuracy: 0.9989 - val_loss: 0.0065 - val_precision: 0.6333 - val_recall: 0.7917\n",
      "Epoch 55/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0025 - precision: 0.9992 - recall: 0.9998 - val_accuracy: 0.9992 - val_loss: 0.0074 - val_precision: 0.7407 - val_recall: 0.8333\n",
      "Epoch 56/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0026 - precision: 0.9992 - recall: 0.9997 - val_accuracy: 0.9992 - val_loss: 0.0085 - val_precision: 0.7143 - val_recall: 0.8333\n",
      "Epoch 57/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0028 - precision: 0.9992 - recall: 0.9998 - val_accuracy: 0.9989 - val_loss: 0.0066 - val_precision: 0.6250 - val_recall: 0.8333\n",
      "Epoch 58/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0025 - precision: 0.9992 - recall: 0.9997 - val_accuracy: 0.9994 - val_loss: 0.0074 - val_precision: 0.8000 - val_recall: 0.8333\n",
      "Epoch 59/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0022 - precision: 0.9993 - recall: 0.9998 - val_accuracy: 0.9990 - val_loss: 0.0068 - val_precision: 0.6667 - val_recall: 0.8333\n",
      "Epoch 60/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0023 - precision: 0.9993 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0056 - val_precision: 0.8000 - val_recall: 0.8333\n",
      "Epoch 61/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0024 - precision: 0.9993 - recall: 0.9997 - val_accuracy: 0.9992 - val_loss: 0.0051 - val_precision: 0.7600 - val_recall: 0.7917\n",
      "Epoch 62/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0023 - precision: 0.9993 - recall: 0.9998 - val_accuracy: 0.9992 - val_loss: 0.0072 - val_precision: 0.7143 - val_recall: 0.8333\n",
      "Epoch 63/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0024 - precision: 0.9993 - recall: 0.9997 - val_accuracy: 0.9990 - val_loss: 0.0056 - val_precision: 0.6667 - val_recall: 0.8333\n",
      "Epoch 64/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0026 - precision: 0.9992 - recall: 0.9997 - val_accuracy: 0.9992 - val_loss: 0.0078 - val_precision: 0.7143 - val_recall: 0.8333\n",
      "Epoch 65/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0023 - precision: 0.9993 - recall: 0.9998 - val_accuracy: 0.9990 - val_loss: 0.0066 - val_precision: 0.6786 - val_recall: 0.7917\n",
      "Epoch 66/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0024 - precision: 0.9994 - recall: 0.9998 - val_accuracy: 0.9992 - val_loss: 0.0057 - val_precision: 0.7407 - val_recall: 0.8333\n",
      "Epoch 67/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0021 - precision: 0.9993 - recall: 0.9998 - val_accuracy: 0.9992 - val_loss: 0.0081 - val_precision: 0.7407 - val_recall: 0.8333\n",
      "Epoch 68/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0024 - precision: 0.9993 - recall: 0.9998 - val_accuracy: 0.9992 - val_loss: 0.0084 - val_precision: 0.7143 - val_recall: 0.8333\n",
      "Epoch 69/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0024 - precision: 0.9991 - recall: 0.9997 - val_accuracy: 0.9992 - val_loss: 0.0071 - val_precision: 0.7407 - val_recall: 0.8333\n",
      "Epoch 70/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0022 - precision: 0.9993 - recall: 0.9998 - val_accuracy: 0.9991 - val_loss: 0.0076 - val_precision: 0.6897 - val_recall: 0.8333\n",
      "Epoch 71/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0023 - precision: 0.9993 - recall: 0.9997 - val_accuracy: 0.9989 - val_loss: 0.0090 - val_precision: 0.6452 - val_recall: 0.8333\n",
      "Epoch 72/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0024 - precision: 0.9993 - recall: 0.9998 - val_accuracy: 0.9991 - val_loss: 0.0084 - val_precision: 0.6897 - val_recall: 0.8333\n",
      "Epoch 73/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0021 - precision: 0.9994 - recall: 0.9998 - val_accuracy: 0.9992 - val_loss: 0.0095 - val_precision: 0.7143 - val_recall: 0.8333\n",
      "Epoch 74/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0021 - precision: 0.9993 - recall: 0.9998 - val_accuracy: 0.9991 - val_loss: 0.0110 - val_precision: 0.6897 - val_recall: 0.8333\n",
      "Epoch 75/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0022 - precision: 0.9993 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0079 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 76/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0020 - precision: 0.9994 - recall: 0.9997 - val_accuracy: 0.9994 - val_loss: 0.0072 - val_precision: 0.8000 - val_recall: 0.8333\n",
      "Epoch 77/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0022 - precision: 0.9993 - recall: 0.9997 - val_accuracy: 0.9994 - val_loss: 0.0095 - val_precision: 0.8000 - val_recall: 0.8333\n",
      "Epoch 78/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0020 - precision: 0.9994 - recall: 0.9998 - val_accuracy: 0.9990 - val_loss: 0.0120 - val_precision: 0.6667 - val_recall: 0.8333\n",
      "Epoch 79/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0020 - precision: 0.9993 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0106 - val_precision: 0.8000 - val_recall: 0.8333\n",
      "Epoch 80/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0021 - precision: 0.9993 - recall: 0.9998 - val_accuracy: 0.9990 - val_loss: 0.0076 - val_precision: 0.6667 - val_recall: 0.8333\n",
      "Epoch 81/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0020 - precision: 0.9994 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0085 - val_precision: 0.8000 - val_recall: 0.8333\n",
      "Epoch 82/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0022 - precision: 0.9994 - recall: 0.9998 - val_accuracy: 0.9992 - val_loss: 0.0090 - val_precision: 0.7407 - val_recall: 0.8333\n",
      "Epoch 83/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0023 - precision: 0.9993 - recall: 0.9998 - val_accuracy: 0.9989 - val_loss: 0.0065 - val_precision: 0.6452 - val_recall: 0.8333\n",
      "Epoch 84/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0022 - precision: 0.9993 - recall: 0.9998 - val_accuracy: 0.9992 - val_loss: 0.0086 - val_precision: 0.7143 - val_recall: 0.8333\n",
      "Epoch 85/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0019 - precision: 0.9994 - recall: 0.9998 - val_accuracy: 0.9992 - val_loss: 0.0098 - val_precision: 0.7407 - val_recall: 0.8333\n",
      "Epoch 86/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0020 - precision: 0.9994 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0091 - val_precision: 0.8333 - val_recall: 0.8333\n",
      "Epoch 87/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0023 - precision: 0.9994 - recall: 0.9998 - val_accuracy: 0.9992 - val_loss: 0.0058 - val_precision: 0.7407 - val_recall: 0.8333\n",
      "Epoch 88/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0021 - precision: 0.9994 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0064 - val_precision: 0.8000 - val_recall: 0.8333\n",
      "Epoch 89/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0020 - precision: 0.9994 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0070 - val_precision: 0.8000 - val_recall: 0.8333\n",
      "Epoch 90/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0019 - precision: 0.9994 - recall: 0.9998 - val_accuracy: 0.9993 - val_loss: 0.0078 - val_precision: 0.7692 - val_recall: 0.8333\n",
      "Epoch 91/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0021 - precision: 0.9993 - recall: 0.9998 - val_accuracy: 0.9991 - val_loss: 0.0068 - val_precision: 0.6897 - val_recall: 0.8333\n",
      "Epoch 92/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0020 - precision: 0.9994 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0100 - val_precision: 0.8000 - val_recall: 0.8333\n",
      "Epoch 93/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0019 - precision: 0.9993 - recall: 0.9998 - val_accuracy: 0.9991 - val_loss: 0.0100 - val_precision: 0.6897 - val_recall: 0.8333\n",
      "Epoch 94/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0019 - precision: 0.9994 - recall: 0.9998 - val_accuracy: 0.9990 - val_loss: 0.0069 - val_precision: 0.6667 - val_recall: 0.8333\n",
      "Epoch 95/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0021 - precision: 0.9993 - recall: 0.9998 - val_accuracy: 0.9993 - val_loss: 0.0085 - val_precision: 0.7692 - val_recall: 0.8333\n",
      "Epoch 96/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0019 - precision: 0.9994 - recall: 0.9998 - val_accuracy: 0.9992 - val_loss: 0.0082 - val_precision: 0.7407 - val_recall: 0.8333\n",
      "Epoch 97/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0021 - precision: 0.9994 - recall: 0.9998 - val_accuracy: 0.9992 - val_loss: 0.0092 - val_precision: 0.7143 - val_recall: 0.8333\n",
      "Epoch 98/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0020 - precision: 0.9995 - recall: 0.9998 - val_accuracy: 0.9992 - val_loss: 0.0091 - val_precision: 0.7407 - val_recall: 0.8333\n",
      "Epoch 99/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0019 - precision: 0.9994 - recall: 0.9998 - val_accuracy: 0.9994 - val_loss: 0.0118 - val_precision: 0.8000 - val_recall: 0.8333\n",
      "Epoch 100/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0023 - precision: 0.9993 - recall: 0.9998 - val_accuracy: 0.9992 - val_loss: 0.0103 - val_precision: 0.7143 - val_recall: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x206031a6390>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model2 = Sequential([\n",
    "\n",
    "    InputLayer(X_train.shape[1:]),\n",
    "    \n",
    "    Dense(256, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.35),\n",
    "\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.35),\n",
    "\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.35),\n",
    "\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.35),\n",
    "\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model2.compile(loss=BinaryCrossentropy(), optimizer=Nadam(learning_rate=0.001), metrics=[\"accuracy\", \"precision\", \"recall\"])\n",
    "model2.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final validation metrics for `model2` were: \n",
    "* Accuracy: 0.99\n",
    "* Precision: 0.71 \n",
    "* Recall: 0.83  \n",
    "\n",
    "Below, `model2` is scored on the testing set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9993 - loss: 0.0116 - precision: 0.7670 - recall: 0.8533     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.016008902341127396,\n",
       " 0.9992977976799011,\n",
       " 0.7419354915618896,\n",
       " 0.9200000166893005]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, the accuracy was nearly perfect, with precision dropping and recall remaining the same. Its still not a bad model, but not quite as good as `model1`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3\n",
    "\n",
    "The third and final model once again contains four 256-unit dense layers which are fed to a dense 32-unit layer and onto the output. However, this time the dropout layers are reduced slightly to 0.3. The SGD optimizer is used in place of Nadam, but the learning rate of 0.001 is maintained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - accuracy: 0.8933 - loss: 0.2603 - precision: 0.9301 - recall: 0.8480 - val_accuracy: 0.9837 - val_loss: 0.0591 - val_precision: 0.0873 - val_recall: 0.9167\n",
      "Epoch 2/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9523 - loss: 0.1200 - precision: 0.9601 - recall: 0.9438 - val_accuracy: 0.9821 - val_loss: 0.0493 - val_precision: 0.0800 - val_recall: 0.9167\n",
      "Epoch 3/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9631 - loss: 0.0924 - precision: 0.9662 - recall: 0.9600 - val_accuracy: 0.9840 - val_loss: 0.0398 - val_precision: 0.0887 - val_recall: 0.9167\n",
      "Epoch 4/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9703 - loss: 0.0761 - precision: 0.9708 - recall: 0.9699 - val_accuracy: 0.9851 - val_loss: 0.0340 - val_precision: 0.0913 - val_recall: 0.8750\n",
      "Epoch 5/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9747 - loss: 0.0649 - precision: 0.9733 - recall: 0.9762 - val_accuracy: 0.9889 - val_loss: 0.0280 - val_precision: 0.1193 - val_recall: 0.8750\n",
      "Epoch 6/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9788 - loss: 0.0555 - precision: 0.9769 - recall: 0.9808 - val_accuracy: 0.9902 - val_loss: 0.0247 - val_precision: 0.1338 - val_recall: 0.8750\n",
      "Epoch 7/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.9816 - loss: 0.0491 - precision: 0.9793 - recall: 0.9840 - val_accuracy: 0.9923 - val_loss: 0.0215 - val_precision: 0.1654 - val_recall: 0.8750\n",
      "Epoch 8/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.0438 - precision: 0.9812 - recall: 0.9868 - val_accuracy: 0.9933 - val_loss: 0.0195 - val_precision: 0.1858 - val_recall: 0.8750\n",
      "Epoch 9/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9858 - loss: 0.0387 - precision: 0.9830 - recall: 0.9887 - val_accuracy: 0.9937 - val_loss: 0.0175 - val_precision: 0.1963 - val_recall: 0.8750\n",
      "Epoch 10/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9876 - loss: 0.0352 - precision: 0.9848 - recall: 0.9905 - val_accuracy: 0.9953 - val_loss: 0.0146 - val_precision: 0.2471 - val_recall: 0.8750\n",
      "Epoch 11/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9892 - loss: 0.0316 - precision: 0.9870 - recall: 0.9916 - val_accuracy: 0.9959 - val_loss: 0.0133 - val_precision: 0.2763 - val_recall: 0.8750\n",
      "Epoch 12/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9902 - loss: 0.0289 - precision: 0.9879 - recall: 0.9926 - val_accuracy: 0.9963 - val_loss: 0.0116 - val_precision: 0.3000 - val_recall: 0.8750\n",
      "Epoch 13/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 0.0265 - precision: 0.9891 - recall: 0.9931 - val_accuracy: 0.9965 - val_loss: 0.0114 - val_precision: 0.3088 - val_recall: 0.8750\n",
      "Epoch 14/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0249 - precision: 0.9895 - recall: 0.9937 - val_accuracy: 0.9965 - val_loss: 0.0115 - val_precision: 0.3088 - val_recall: 0.8750\n",
      "Epoch 15/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0236 - precision: 0.9901 - recall: 0.9945 - val_accuracy: 0.9971 - val_loss: 0.0109 - val_precision: 0.3559 - val_recall: 0.8750\n",
      "Epoch 16/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0230 - precision: 0.9904 - recall: 0.9943 - val_accuracy: 0.9971 - val_loss: 0.0106 - val_precision: 0.3500 - val_recall: 0.8750\n",
      "Epoch 17/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0211 - precision: 0.9911 - recall: 0.9951 - val_accuracy: 0.9972 - val_loss: 0.0100 - val_precision: 0.3621 - val_recall: 0.8750\n",
      "Epoch 18/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9936 - loss: 0.0202 - precision: 0.9919 - recall: 0.9952 - val_accuracy: 0.9976 - val_loss: 0.0098 - val_precision: 0.4038 - val_recall: 0.8750\n",
      "Epoch 19/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - accuracy: 0.9939 - loss: 0.0193 - precision: 0.9922 - recall: 0.9956 - val_accuracy: 0.9976 - val_loss: 0.0093 - val_precision: 0.4038 - val_recall: 0.8750\n",
      "Epoch 20/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3ms/step - accuracy: 0.9941 - loss: 0.0182 - precision: 0.9924 - recall: 0.9959 - val_accuracy: 0.9976 - val_loss: 0.0094 - val_precision: 0.4038 - val_recall: 0.8750\n",
      "Epoch 21/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9945 - loss: 0.0175 - precision: 0.9929 - recall: 0.9961 - val_accuracy: 0.9976 - val_loss: 0.0093 - val_precision: 0.4038 - val_recall: 0.8750\n",
      "Epoch 22/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9949 - loss: 0.0165 - precision: 0.9935 - recall: 0.9964 - val_accuracy: 0.9977 - val_loss: 0.0094 - val_precision: 0.4118 - val_recall: 0.8750\n",
      "Epoch 23/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9949 - loss: 0.0158 - precision: 0.9934 - recall: 0.9964 - val_accuracy: 0.9977 - val_loss: 0.0089 - val_precision: 0.4118 - val_recall: 0.8750\n",
      "Epoch 24/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9952 - loss: 0.0154 - precision: 0.9938 - recall: 0.9966 - val_accuracy: 0.9978 - val_loss: 0.0089 - val_precision: 0.4286 - val_recall: 0.8750\n",
      "Epoch 25/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9954 - loss: 0.0148 - precision: 0.9941 - recall: 0.9968 - val_accuracy: 0.9979 - val_loss: 0.0089 - val_precision: 0.4375 - val_recall: 0.8750\n",
      "Epoch 26/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9956 - loss: 0.0147 - precision: 0.9943 - recall: 0.9969 - val_accuracy: 0.9979 - val_loss: 0.0087 - val_precision: 0.4375 - val_recall: 0.8750\n",
      "Epoch 27/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9957 - loss: 0.0138 - precision: 0.9944 - recall: 0.9971 - val_accuracy: 0.9978 - val_loss: 0.0093 - val_precision: 0.4200 - val_recall: 0.8750\n",
      "Epoch 28/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9959 - loss: 0.0135 - precision: 0.9945 - recall: 0.9973 - val_accuracy: 0.9981 - val_loss: 0.0084 - val_precision: 0.4651 - val_recall: 0.8333\n",
      "Epoch 29/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.9962 - loss: 0.0129 - precision: 0.9950 - recall: 0.9974 - val_accuracy: 0.9980 - val_loss: 0.0084 - val_precision: 0.4468 - val_recall: 0.8750\n",
      "Epoch 30/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9963 - loss: 0.0124 - precision: 0.9951 - recall: 0.9975 - val_accuracy: 0.9981 - val_loss: 0.0081 - val_precision: 0.4651 - val_recall: 0.8333\n",
      "Epoch 31/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9963 - loss: 0.0126 - precision: 0.9950 - recall: 0.9975 - val_accuracy: 0.9982 - val_loss: 0.0079 - val_precision: 0.4878 - val_recall: 0.8333\n",
      "Epoch 32/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9964 - loss: 0.0122 - precision: 0.9954 - recall: 0.9975 - val_accuracy: 0.9985 - val_loss: 0.0080 - val_precision: 0.5263 - val_recall: 0.8333\n",
      "Epoch 33/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9965 - loss: 0.0117 - precision: 0.9956 - recall: 0.9975 - val_accuracy: 0.9982 - val_loss: 0.0080 - val_precision: 0.4878 - val_recall: 0.8333\n",
      "Epoch 34/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9966 - loss: 0.0117 - precision: 0.9956 - recall: 0.9976 - val_accuracy: 0.9983 - val_loss: 0.0079 - val_precision: 0.5000 - val_recall: 0.8750\n",
      "Epoch 35/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9968 - loss: 0.0108 - precision: 0.9959 - recall: 0.9978 - val_accuracy: 0.9985 - val_loss: 0.0075 - val_precision: 0.5263 - val_recall: 0.8333\n",
      "Epoch 36/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9969 - loss: 0.0109 - precision: 0.9959 - recall: 0.9979 - val_accuracy: 0.9985 - val_loss: 0.0077 - val_precision: 0.5405 - val_recall: 0.8333\n",
      "Epoch 37/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9970 - loss: 0.0107 - precision: 0.9961 - recall: 0.9979 - val_accuracy: 0.9985 - val_loss: 0.0076 - val_precision: 0.5405 - val_recall: 0.8333\n",
      "Epoch 38/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9969 - loss: 0.0106 - precision: 0.9959 - recall: 0.9980 - val_accuracy: 0.9986 - val_loss: 0.0072 - val_precision: 0.5556 - val_recall: 0.8333\n",
      "Epoch 39/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9971 - loss: 0.0100 - precision: 0.9963 - recall: 0.9980 - val_accuracy: 0.9987 - val_loss: 0.0074 - val_precision: 0.5714 - val_recall: 0.8333\n",
      "Epoch 40/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9971 - loss: 0.0101 - precision: 0.9962 - recall: 0.9981 - val_accuracy: 0.9986 - val_loss: 0.0072 - val_precision: 0.5588 - val_recall: 0.7917\n",
      "Epoch 41/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9972 - loss: 0.0095 - precision: 0.9963 - recall: 0.9982 - val_accuracy: 0.9987 - val_loss: 0.0074 - val_precision: 0.5882 - val_recall: 0.8333\n",
      "Epoch 42/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9973 - loss: 0.0094 - precision: 0.9964 - recall: 0.9982 - val_accuracy: 0.9987 - val_loss: 0.0072 - val_precision: 0.5882 - val_recall: 0.8333\n",
      "Epoch 43/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9974 - loss: 0.0094 - precision: 0.9965 - recall: 0.9982 - val_accuracy: 0.9988 - val_loss: 0.0070 - val_precision: 0.6061 - val_recall: 0.8333\n",
      "Epoch 44/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9975 - loss: 0.0091 - precision: 0.9967 - recall: 0.9983 - val_accuracy: 0.9988 - val_loss: 0.0072 - val_precision: 0.6061 - val_recall: 0.8333\n",
      "Epoch 45/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9974 - loss: 0.0088 - precision: 0.9966 - recall: 0.9983 - val_accuracy: 0.9986 - val_loss: 0.0075 - val_precision: 0.5556 - val_recall: 0.8333\n",
      "Epoch 46/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - accuracy: 0.9975 - loss: 0.0088 - precision: 0.9967 - recall: 0.9983 - val_accuracy: 0.9988 - val_loss: 0.0071 - val_precision: 0.6129 - val_recall: 0.7917\n",
      "Epoch 47/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9975 - loss: 0.0090 - precision: 0.9966 - recall: 0.9984 - val_accuracy: 0.9987 - val_loss: 0.0071 - val_precision: 0.5882 - val_recall: 0.8333\n",
      "Epoch 48/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9975 - loss: 0.0090 - precision: 0.9968 - recall: 0.9983 - val_accuracy: 0.9988 - val_loss: 0.0072 - val_precision: 0.6061 - val_recall: 0.8333\n",
      "Epoch 49/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9976 - loss: 0.0084 - precision: 0.9969 - recall: 0.9984 - val_accuracy: 0.9988 - val_loss: 0.0071 - val_precision: 0.6129 - val_recall: 0.7917\n",
      "Epoch 50/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9977 - loss: 0.0081 - precision: 0.9970 - recall: 0.9985 - val_accuracy: 0.9988 - val_loss: 0.0071 - val_precision: 0.6129 - val_recall: 0.7917\n",
      "Epoch 51/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9976 - loss: 0.0084 - precision: 0.9969 - recall: 0.9983 - val_accuracy: 0.9988 - val_loss: 0.0071 - val_precision: 0.6129 - val_recall: 0.7917\n",
      "Epoch 52/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 0.0079 - precision: 0.9972 - recall: 0.9986 - val_accuracy: 0.9988 - val_loss: 0.0071 - val_precision: 0.6061 - val_recall: 0.8333\n",
      "Epoch 53/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 0.0077 - precision: 0.9973 - recall: 0.9985 - val_accuracy: 0.9989 - val_loss: 0.0069 - val_precision: 0.6250 - val_recall: 0.8333\n",
      "Epoch 54/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 0.0079 - precision: 0.9972 - recall: 0.9986 - val_accuracy: 0.9987 - val_loss: 0.0072 - val_precision: 0.5882 - val_recall: 0.8333\n",
      "Epoch 55/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 0.0078 - precision: 0.9972 - recall: 0.9986 - val_accuracy: 0.9988 - val_loss: 0.0071 - val_precision: 0.6061 - val_recall: 0.8333\n",
      "Epoch 56/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 0.0077 - precision: 0.9973 - recall: 0.9986 - val_accuracy: 0.9989 - val_loss: 0.0071 - val_precision: 0.6452 - val_recall: 0.8333\n",
      "Epoch 57/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9980 - loss: 0.0075 - precision: 0.9973 - recall: 0.9987 - val_accuracy: 0.9988 - val_loss: 0.0070 - val_precision: 0.6129 - val_recall: 0.7917\n",
      "Epoch 58/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9980 - loss: 0.0074 - precision: 0.9973 - recall: 0.9988 - val_accuracy: 0.9989 - val_loss: 0.0070 - val_precision: 0.6250 - val_recall: 0.8333\n",
      "Epoch 59/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9981 - loss: 0.0070 - precision: 0.9974 - recall: 0.9988 - val_accuracy: 0.9989 - val_loss: 0.0067 - val_precision: 0.6552 - val_recall: 0.7917\n",
      "Epoch 60/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9980 - loss: 0.0073 - precision: 0.9974 - recall: 0.9987 - val_accuracy: 0.9990 - val_loss: 0.0068 - val_precision: 0.6786 - val_recall: 0.7917\n",
      "Epoch 61/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9981 - loss: 0.0071 - precision: 0.9974 - recall: 0.9988 - val_accuracy: 0.9988 - val_loss: 0.0071 - val_precision: 0.6129 - val_recall: 0.7917\n",
      "Epoch 62/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 0.0075 - precision: 0.9973 - recall: 0.9986 - val_accuracy: 0.9990 - val_loss: 0.0068 - val_precision: 0.6786 - val_recall: 0.7917\n",
      "Epoch 63/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0066 - precision: 0.9976 - recall: 0.9989 - val_accuracy: 0.9990 - val_loss: 0.0067 - val_precision: 0.6786 - val_recall: 0.7917\n",
      "Epoch 64/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0068 - precision: 0.9975 - recall: 0.9988 - val_accuracy: 0.9990 - val_loss: 0.0067 - val_precision: 0.6786 - val_recall: 0.7917\n",
      "Epoch 65/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9983 - loss: 0.0064 - precision: 0.9978 - recall: 0.9989 - val_accuracy: 0.9989 - val_loss: 0.0065 - val_precision: 0.6552 - val_recall: 0.7917\n",
      "Epoch 66/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0067 - precision: 0.9976 - recall: 0.9989 - val_accuracy: 0.9989 - val_loss: 0.0067 - val_precision: 0.6333 - val_recall: 0.7917\n",
      "Epoch 67/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9984 - loss: 0.0062 - precision: 0.9978 - recall: 0.9990 - val_accuracy: 0.9989 - val_loss: 0.0068 - val_precision: 0.6552 - val_recall: 0.7917\n",
      "Epoch 68/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9983 - loss: 0.0064 - precision: 0.9977 - recall: 0.9988 - val_accuracy: 0.9989 - val_loss: 0.0068 - val_precision: 0.6552 - val_recall: 0.7917\n",
      "Epoch 69/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9983 - loss: 0.0067 - precision: 0.9977 - recall: 0.9990 - val_accuracy: 0.9990 - val_loss: 0.0065 - val_precision: 0.6786 - val_recall: 0.7917\n",
      "Epoch 70/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - accuracy: 0.9983 - loss: 0.0065 - precision: 0.9978 - recall: 0.9988 - val_accuracy: 0.9989 - val_loss: 0.0067 - val_precision: 0.6552 - val_recall: 0.7917\n",
      "Epoch 71/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9984 - loss: 0.0062 - precision: 0.9978 - recall: 0.9990 - val_accuracy: 0.9990 - val_loss: 0.0066 - val_precision: 0.6786 - val_recall: 0.7917\n",
      "Epoch 72/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9983 - loss: 0.0062 - precision: 0.9977 - recall: 0.9989 - val_accuracy: 0.9990 - val_loss: 0.0065 - val_precision: 0.6786 - val_recall: 0.7917\n",
      "Epoch 73/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0058 - precision: 0.9979 - recall: 0.9991 - val_accuracy: 0.9991 - val_loss: 0.0066 - val_precision: 0.7037 - val_recall: 0.7917\n",
      "Epoch 74/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0060 - precision: 0.9979 - recall: 0.9990 - val_accuracy: 0.9989 - val_loss: 0.0067 - val_precision: 0.6552 - val_recall: 0.7917\n",
      "Epoch 75/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0058 - precision: 0.9979 - recall: 0.9990 - val_accuracy: 0.9991 - val_loss: 0.0066 - val_precision: 0.7037 - val_recall: 0.7917\n",
      "Epoch 76/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0058 - precision: 0.9979 - recall: 0.9991 - val_accuracy: 0.9991 - val_loss: 0.0065 - val_precision: 0.7037 - val_recall: 0.7917\n",
      "Epoch 77/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0060 - precision: 0.9979 - recall: 0.9990 - val_accuracy: 0.9990 - val_loss: 0.0065 - val_precision: 0.6786 - val_recall: 0.7917\n",
      "Epoch 78/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9984 - loss: 0.0061 - precision: 0.9979 - recall: 0.9990 - val_accuracy: 0.9991 - val_loss: 0.0065 - val_precision: 0.7037 - val_recall: 0.7917\n",
      "Epoch 79/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0059 - precision: 0.9981 - recall: 0.9989 - val_accuracy: 0.9991 - val_loss: 0.0064 - val_precision: 0.7037 - val_recall: 0.7917\n",
      "Epoch 80/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0056 - precision: 0.9981 - recall: 0.9991 - val_accuracy: 0.9991 - val_loss: 0.0065 - val_precision: 0.7037 - val_recall: 0.7917\n",
      "Epoch 81/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0053 - precision: 0.9981 - recall: 0.9992 - val_accuracy: 0.9991 - val_loss: 0.0065 - val_precision: 0.7037 - val_recall: 0.7917\n",
      "Epoch 82/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0054 - precision: 0.9982 - recall: 0.9991 - val_accuracy: 0.9991 - val_loss: 0.0065 - val_precision: 0.7037 - val_recall: 0.7917\n",
      "Epoch 83/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0057 - precision: 0.9982 - recall: 0.9991 - val_accuracy: 0.9991 - val_loss: 0.0063 - val_precision: 0.7037 - val_recall: 0.7917\n",
      "Epoch 84/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0054 - precision: 0.9981 - recall: 0.9990 - val_accuracy: 0.9991 - val_loss: 0.0065 - val_precision: 0.7037 - val_recall: 0.7917\n",
      "Epoch 85/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0057 - precision: 0.9981 - recall: 0.9991 - val_accuracy: 0.9991 - val_loss: 0.0064 - val_precision: 0.7037 - val_recall: 0.7917\n",
      "Epoch 86/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0053 - precision: 0.9981 - recall: 0.9992 - val_accuracy: 0.9991 - val_loss: 0.0064 - val_precision: 0.7037 - val_recall: 0.7917\n",
      "Epoch 87/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0052 - precision: 0.9981 - recall: 0.9992 - val_accuracy: 0.9989 - val_loss: 0.0066 - val_precision: 0.6552 - val_recall: 0.7917\n",
      "Epoch 88/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0055 - precision: 0.9981 - recall: 0.9990 - val_accuracy: 0.9992 - val_loss: 0.0064 - val_precision: 0.7143 - val_recall: 0.8333\n",
      "Epoch 89/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0054 - precision: 0.9982 - recall: 0.9991 - val_accuracy: 0.9991 - val_loss: 0.0064 - val_precision: 0.7037 - val_recall: 0.7917\n",
      "Epoch 90/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0051 - precision: 0.9983 - recall: 0.9992 - val_accuracy: 0.9991 - val_loss: 0.0064 - val_precision: 0.7037 - val_recall: 0.7917\n",
      "Epoch 91/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0048 - precision: 0.9981 - recall: 0.9993 - val_accuracy: 0.9991 - val_loss: 0.0064 - val_precision: 0.7037 - val_recall: 0.7917\n",
      "Epoch 92/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0046 - precision: 0.9985 - recall: 0.9993 - val_accuracy: 0.9991 - val_loss: 0.0064 - val_precision: 0.7037 - val_recall: 0.7917\n",
      "Epoch 93/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0051 - precision: 0.9982 - recall: 0.9992 - val_accuracy: 0.9990 - val_loss: 0.0064 - val_precision: 0.6786 - val_recall: 0.7917\n",
      "Epoch 94/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0048 - precision: 0.9983 - recall: 0.9992 - val_accuracy: 0.9991 - val_loss: 0.0064 - val_precision: 0.7037 - val_recall: 0.7917\n",
      "Epoch 95/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0050 - precision: 0.9983 - recall: 0.9993 - val_accuracy: 0.9991 - val_loss: 0.0064 - val_precision: 0.7037 - val_recall: 0.7917\n",
      "Epoch 96/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0051 - precision: 0.9983 - recall: 0.9991 - val_accuracy: 0.9991 - val_loss: 0.0064 - val_precision: 0.7037 - val_recall: 0.7917\n",
      "Epoch 97/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0048 - precision: 0.9983 - recall: 0.9992 - val_accuracy: 0.9991 - val_loss: 0.0062 - val_precision: 0.7037 - val_recall: 0.7917\n",
      "Epoch 98/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0050 - precision: 0.9983 - recall: 0.9993 - val_accuracy: 0.9991 - val_loss: 0.0064 - val_precision: 0.7037 - val_recall: 0.7917\n",
      "Epoch 99/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0046 - precision: 0.9985 - recall: 0.9993 - val_accuracy: 0.9991 - val_loss: 0.0062 - val_precision: 0.7037 - val_recall: 0.7917\n",
      "Epoch 100/100\n",
      "\u001b[1m15993/15993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0048 - precision: 0.9983 - recall: 0.9992 - val_accuracy: 0.9991 - val_loss: 0.0063 - val_precision: 0.7037 - val_recall: 0.7917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2060bcf3c80>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model3 = Sequential([\n",
    "\n",
    "    InputLayer(X_train.shape[1:]),\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model3.compile(loss=BinaryCrossentropy(), optimizer=SGD(learning_rate=0.001), metrics=[\"accuracy\", \"precision\", \"recall\"])\n",
    "model3.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final validation metrics for `model3` were: \n",
    "* Accuracy: 0.99\n",
    "* Precision: 0.70\n",
    "* Recall: 0.79\n",
    "\n",
    "Below, `model3` is scored on the testing set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9992 - loss: 0.0075 - precision: 0.7212 - recall: 0.8533        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.006295042112469673, 0.9992275834083557, 0.71875, 0.9200000166893005]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy and recall results remain the same, with the precision score being the lowest out of all three models. \n",
    "\n",
    "> Note that the testing recall score is the same between all three models. This is due to the fact that the validation and testing sets were not oversampled, resulting in each having relatively few positive instances for the models to predict.\n",
    "\n",
    "\n",
    "### Summary of Models\n",
    "\n",
    "In the end, `model1` performed the best out of the three. Based on the test data, it is reasonable to assume that, in the real world, the model would catch the majority of fraud, while also keeping false positives positives to a minimum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application\n",
    "\n",
    "Now that `model1` has been trained, it can be used in real world programs. However, it first needs to be exported to a `.keras` file, which can be called by other Python programs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save(\"model1.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The world of finance has grown rapidly in the internet age, bringing with it new opportunities for fraud. With the age of AI upon us, new technologies will inevitably be used by malicious actors to find new ways to circumvent security measures and cause irreparable damage to innocent people. The good news is that AI can also be used to help prevent fraudsters' attempts at stealing from customers and companies alike, creating a new era of security for in a sector that affects so many lives. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
